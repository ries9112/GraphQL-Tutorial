---
title: "API & GraphQL Tutorial"
output: 
  learnr::tutorial:
    theme: spacelab
    progressive: true
runtime: shiny_prerendered
bibliography: packages.bib
---

```{r setup, include=FALSE}
library(learnr)
library(knitr)
library(tibble)
library(tidyr)
library(httr)
library(jsonlite)
library(reticulate)
library(dplyr)
# set scientific notation
options(scipen=999)

# setup data needed at a global level for exercise chunks:
url <- "https://jobs.github.com/positions.json"
# Get the data from the url and convert to dataframe
github_jobs <- fromJSON(content(GET(url), as='text'))
# Modify the url for the API request for New York location
url <- paste0(url, "?location=new+york")
# Get the data from the url and convert to dataframe
github_jobs_nyc <- fromJSON(content(GET(url), as='text'))

# setup orderbook as global variable
cryptocurrency <- "BTC"
# Build the url for the API request
url <- paste0("https://api.hitbtc.com/api/2/public/orderbook/",cryptocurrency,"USD")
# Get the data from the url
orderbook <- content(GET(url), as='text')
# Convert from JSON to dataframe
orderbook <- fromJSON(orderbook)
```

<!-- css below doesn't show anything, it limits the code chunks to a certain size in case any of the results show really large outputs -->

```{css adjust_height, echo=FALSE}
pre {
  max-height: 400px;
  overflow-y: auto;
}

pre[class] {
  max-height: 200px;
}
```

## APIs Introduction

An API is a tool that helps share data/information with anyone. APIs are frequently created by companies to allow developers to create software that allows users to interact with their services. Some are more complex than others, so for the purposes of this tutorial **we will only use APIs that require no authentication**.

The word API stands for **A**pplication **P**rogramming **I**nterface. APIs are meant to be accessible regardless of the programming language used. The data can be accessed through a URL the same way you would access a website, but typically returns very light text in the JSON format, which we will have to then manipulate to a format that works better in R and Python which will look like a data table with rows and columns. APIs provide a way for anyone to interact with a service through code, which can be as simple as pulling some data, or more complex, for example to programmatically trigger a trade on a cryptocurrency exchange. APIs are used by a large number of entities for different purposes, for example the US government provides data that anyone can perform research on: https://www.data.gov/developers/apis (which we will not use in this tutorial because it requires the user to request a free API "key" to authenticate).

<!-- To give another concrete example of an API, Strava - add this example? Discussing how you can use their app to track your progress, or create your own reports - could give example using blog post shared on the R Strava group, but obviously would need to keep that part of the code hidden if posting to GitHub -->

### API Usage

<!-- If needed, list of postman public endpoints that do not require authentication: https://documenter.getpostman.com/view/8854915/Szf7znEe -->

Let's start with a simple example relating to the TV show Game of Thrones. We can get information relating to the different houses by navigating to this url: https://www.anapioficeandfire.com/api/houses

The webpage is shown below:

```{r show_GoT_url, echo=F}
knitr::include_url("https://www.anapioficeandfire.com/api/houses")
```

In order to get this information into R or another programming language, we will need to perform a ***GET*** request to retrieve the data from the url above. We can use the `httr` [[@R-httr]](<https://CRAN.R-project.org/package=httr>) package and use the **`GET`** function to receive data from the API:

```{r get_GoT, message=F}
library(httr)
api_request <- GET("https://www.anapioficeandfire.com/api/houses")
```

Using a GET request we can retrieve the data that we are interested in. APIs also sometimes allow users to make **POST** requests which allows the user to **send** data to the service rather than receiving it. Doing a POST requires the user to be authenticated, so in this tutorial we will only be doing GET requests using public API *endpoints*. An endpoint being a url like the one we used above.

If we view the result of the GET request we made, we will see a summary of the results of the request rather than the results themselves:

```{r show_GoT_req}
api_request
```

The result **`Status: 200`** indicates our request was successful. If the request we made was not successful, we would get a different status code, and we could write the logic in our code accordingly to deal with these outcomes. See [this link for a full list of typical status codes and what they would mean](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status).

Because we are interested in the actual content of the request, we can use the function `content()` from the `httr` package on the API request we made and retrieve the text of the content:

```{r show_GoT_content}
# Get the data from the url
example_data <- content(api_request, as='text')
# show the data in its raw format (not yet usable)
example_data
```

In order to convert the data to a tabular format with rows and columns, we can use the `jsonlite` [[@R-jsonlite]](<https://arxiv.org/abs/1403.2805>) package to easily convert the JSON format to a dataframe (the standard way of storing tabular data in R and what Python's pandas uses) by using the `fromJSON()` function:

```{r convert_GoT_show_df, message=FALSE, eval=FALSE}
library(jsonlite)
# Convert from JSON to dataframe
example_data <- fromJSON(example_data)
# Show dataframe
example_data
```
***Use the arrow in the top right of the table to view the rest of the columns.***

<!-- Start by showing name and region instead of url which takes up a lot of room, better default view: -->

```{r convert_GoT_show_df-hidden, echo=FALSE}
library(jsonlite)
# Convert from JSON to dataframe
example_data <- fromJSON(example_data)
# Show dataframe
select(example_data, name, region, url, coatOfArms, words, titles, seats, currentLord, heir, 
       overlord, founded, founder, diedOut, ancestralWeapons, cadetBranches, swornMembers)
```

### Example - GitHub Job Board API

The first example given used data that does not update over time, but in many cases APIs can be used to collect data that evolves over time. To illustrate this point, the example below shows the most recent jobs posted to the [GitHub jobs board](https://jobs.github.com/) as of the moment this tutorial was launched:

```{r pull_github_jobs_data}
url <- "https://jobs.github.com/positions.json"
# Get the data from the url and convert to dataframe
github_jobs <- fromJSON(content(GET(url), as='text'))
# Show data
github_jobs 
```
***The results are limited to the most recent 50 jobs posted.***

To illustrate the point that the data refreshes over time, let's just show the job name, when it was posted, and the url to the job posting.

```{r github_jobs_show_date_posted}
select(github_jobs, created_at, title, url)
```

When we are interested in a specific subset of the data, there are usually ways to modify the request to return the data we need. For example, rather than returning all job postings we could make a request to only get jobs with the location set to New York. To do this, we can add the text `?location=new+york` to the url of the API request:

```{r github_jobs_nyc}
# Modify the url for the API request for New York location
url <- paste0(url, "?location=new+york")
# Get the data from the url and convert to dataframe
github_jobs_nyc <- fromJSON(content(GET(url), as='text'))
# Show data
github_jobs_nyc
```

Use the arrow in the top right corner of the table above to see the content of the different columns. Let's take a closer look at the field `company_logo` which contains the url address to the company logo associated with the job listing:

```{r remove_missing_logos, include=F}
github_jobs <- tidyr::drop_na(github_jobs, company_logo)
```


```{r show_logo}
github_jobs$company_logo
```

By making a request at this url, we can display the image. See the example below showing the **first** company logo of the data (if there is one):

```{r show_logo_first_element, out.height="180px", out.width="300px", error=T}
include_graphics(github_jobs$company_logo[[1]])
```

You can also navigate to the url for the job listing: `r github_jobs$url[[1]]`

Play around with the results of the API request we made. The example below returns the maximum value of the `created_at` field, meaning the date and time the most recent job posting was created:

```{r github_results, exercise=TRUE}
max(github_jobs$created_at)
```

```{r github_results-hint}
# Show the logo of the 5th job listing
include_graphics(github_jobs$company_logo[[5]])
```

To give another example, we could also return results that match the text ***python*** in their description:

```{r show_github_python_jobs}
fromJSON(content(GET("https://jobs.github.com/positions.json?description=python"), as='text'))
```

Notice that on our end we do not need to worry about storing any information or creating any infrastructure, for example we do not need to worry about the difficulties that may come with storing a large amount of images and data, we can simply retrieve specifically what we need.

Towards the end of this tutorial you will learn about a newer technology that is similar to APIs called **GraphQL** which not only allows the user to specify the subset of the data they want to retrieve, but also allows the user to specify which fields to return for the request. For example, if we were only interested in displaying the company logos for the job listings, rather than pulling all of the fields associated with the API request we could be more efficient and create a request that only gives the one field. Before learning how to connect to and use a GraphQL endpoint, move on to the next section to get more practice using regular APIs, this time in the context of collecting prices from the cryptocurrency markets.

## Cryptocurrency Data Examples

### Price of Bitcoin

There are several free APIs we can use to retrieve cryptocurrency prices. 

As a first example, let's get the latest price of Bitcoin according to the website coindesk.com from the url: https://api.coindesk.com/v1/bpi/currentprice.json

<!-- One more example, crypto data: -->

<!-- https://api.coindesk.com/v1/bpi/currentprice.json -->

```{r pull_BTC_price, message=FALSE, warning=FALSE}
url <- "https://api.coindesk.com/v1/bpi/currentprice.json"
# Get the data from the url
bitcoin_price <- content(GET(url), as='text')
# Convert from JSON to dataframe
bitcoin_price <- fromJSON(bitcoin_price)
```

Now we can show the current price of Bitcoin in USD:

```{r show_BTC_price}
bitcoin_price$bpi$USD$rate
```

And when the price was last updated:

```{r show_BTC_data_refresh}
bitcoin_price$time$updated
```

### HitBTC Exchange

The price we showed for Bitcoin is a simplified way of thinking of the price of a cryptocurrency and was the average price across many exchanges. In reality though, the market on an individual exchange is more complicated than a single price, and is instead made up of constantly evolving orders of people who are looking to buy and people who are looking to sell. Users submit their orders to the **order book** and the exchange takes care of filling orders matching buyers and sellers based on their designated price. We can use the API for the [HitBTC exchange](https://hitbtc.com/) to return the 100 most favorable prices on each side of the current order book for Bitcoin (using the BTC/USD trading pair):

```{r HitBTC_price, message=FALSE, warning=FALSE}
url <- "https://api.hitbtc.com/api/2/public/orderbook/BTCUSD"
# Get the data from the url
orderbook <- content(GET(url), as='text')
# Convert from JSON to dataframe
orderbook <- fromJSON(orderbook)
# Show the new data
orderbook
```

The `ask` column gives the current 100 open orders with the lowest asking price, meaning these orders are waiting for someone to purchase the cryptocurrency at the given price point:

```{r ask_price}
orderbook$ask
```

The `bid` price is always going to be lower than orders on the `ask` side of the orderbook, because the second someone tries to purchase the cryptocurrency at a price that is higher than the lowest `ask` price, the `bid` order will immediately be filled:

```{r bid_price}
orderbook$bid
```

We can think of the intersection between the `ask` and the `bid` prices available on the orderbook as the current price. Going back to the example from earlier with Bitcoin's price, we have now seen that this is a bit of a construct because the price of Bitcoin not only depends on the individual exchange, but in practice there is a difference between the price you can purchase Bitcoin at and the price you can sell it for. Because Bitcoin has a large amount of liquidity, this difference tends to be intangible, but if trading other cryptocurrencies with less volume, this can become a meaningful difference.

```{r quiz1, echo=FALSE}
quiz(caption = "Answer below:",
  question("What is the current cheapest price you can buy Bitcoin for on the HitBTC exchange?",
    answer(as.character(as.numeric(orderbook$ask[1,]$price)+213.01)),
    answer(as.character(as.numeric(orderbook$bid[1,]$price)+0.01)),
    answer(as.character(as.numeric(orderbook$ask[1,]$price)), correct = TRUE),
    answer(as.character(as.numeric(orderbook$ask[1,]$price)-40.03))
  )
)
```

Use the code below to change the cryptocurrency price you want to return and make a new API request. For example, you could modify the code to run for the "BTC" cryptocurrency instead of "ETH" and run the code again (see hint):

```{r hitbtc_exercise_data_pull, exercise=TRUE, message=FALSE, warning=FALSE}
# Change the cryptocurrency you want to return prices for:
cryptocurrency <- "ETH"

# Build the url for the API request:
url <- paste0("https://api.hitbtc.com/api/2/public/orderbook/",cryptocurrency,"USD")

# Get the data from the url
orderbook <- content(GET(url), as='text')

# Convert from JSON to dataframe
orderbook <- fromJSON(orderbook)

# Show the lowest `ask` price at which we could purchase the cryptocurrency:
orderbook$ask
```

```{r hitbtc_exercise_data_pull-hint}
# Change the cryptocurrency you want to return prices for:
cryptocurrency <- "BTC"
# Build the url for the API request
url <- paste0("https://api.hitbtc.com/api/2/public/orderbook/",cryptocurrency,"USD")
# Get the data from the url
orderbook <- content(GET(url), as='text')
# Convert from JSON to dataframe
orderbook <- fromJSON(orderbook)
# Show the highest `bid` price at which we could sell the cryptocurrency:
orderbook$bid
```

<!-- Both collecting the price of a cryptocurrency from the perspective of the orderbook, and getting the price at a global level have legitimate use-cases -->

### Coinpaprika API

Congrats on learning about using APIs through R! If you are interested in cryptocurrency market data, we recommend checking out the free API by the the website coinpaprika.com, which is **free and has a huge amount of functionality**. See the documentation for the API here: https://api.coinpaprika.com/

```{r coinpaprika_api_docs, echo=F, out.width="100%"}
knitr::include_url("https://api.coinpaprika.com/")
```

For example, here is a request for all markets that Bitcoin trades on (limited to 1,000 results):

```{r btc_exchanges_coinpaprika, warning=F, message=F}
as.data.frame(fromJSON(content(GET("https://api.coinpaprika.com/v1/coins/btc-bitcoin/markets"), as='text')))
```

Try to modify the request below to show the **`twitter`** endpoint for the **`eth-ethereum`** cryptocurrency (use the hint as needed):

```{r coinpaprika_sandbox, warning=F, message=F, exercise=T}
# Change the url below to a different API endpoint
url <- "https://api.coinpaprika.com/v1/coins/btc-bitcoin/exchanges" # <- change the url
# Pull, parse, and display the data (no need to change the code below)
as.data.frame(fromJSON(content(GET(url), as='text')))
```

```{r coinpaprika_sandbox-hint, hint=T}
# This example changed the endpoint to be for twitter data and for Ethereum
url <- "https://api.coinpaprika.com/v1/coins/eth-ethereum/twitter" # <- twitter example
# Pull, parse, and display the data (no need to change the code below)
as.data.frame(fromJSON(content(GET(url), as='text')))
```

<!-- ## Python Example - COMMENTED OUT BECAUSE REQUEST PACKAGE NOT FOUND--> 

<!-- Making an API request in Python involves the same steps that we have outlined up to this point using R, and would just involve a different set of tools. -->

<!-- For an API request in Python you can use the [**`requests`** library](https://2.python-requests.org/en/master/): -->

<!-- ```{python py_make_request} -->
<!-- import requests -->
<!-- # Make an API request -->
<!-- python_request = requests.get("https://api.coinpaprika.com/v1/coins/btc-bitcoin/exchanges") -->
<!-- ``` -->

<!-- Like before, if we call the result we will get a summary of our request, where a code of **`200`** is a successful request: -->

<!-- ```{python py_show_request} -->
<!-- python_request -->
<!-- ``` -->

<!-- Meaning, we need to actually extract the JSON data out of our request: -->
<!-- ```{python py_json_parse} -->
<!-- python_request = python_request.json() -->
<!-- # Show the data in the json format: -->
<!-- python_request -->
<!-- ``` -->

<!-- Now we can use [**`pandas`**](https://pandas.pydata.org/) to convert the data to a dataframe: -->

<!-- ```{python py_req_to_pandas} -->
<!-- import pandas as pd -->
<!-- python_request = pd.DataFrame(python_request) -->
<!-- ``` -->

<!-- Now we can view the results (shown from R to improve the format): -->

<!-- ```{r show_python_request} -->
<!-- py$python_request -->
<!-- ``` -->


## GraphQL

In all of the previous examples we made specific requests to different URLs to return some data. When making the request, if we are only interested in returning one field, for example only the company logo from the GitHub job board, we would have to request a lot of redundant information to get to the single piece of information that we are interested in.

GraphQL helps solve this problem, and allows for a company/entity to provide an API where the user is able to specify the specific fields they want to return when making their API request, which, depending on the specific situation, can be much more efficient for both the developer of the API and the user.

### GraphQL Example

<!-- TODO - Introduce SpaceX example and interactive explorer -->

The company SpaceX offers a public GraphQL endpoint: https://api.spacex.land/graphql/ - embedded below:

```{r graphql_spacex, out.height="800px", out.width="100%", echo=F}
include_url("https://api.spacex.land/graphql/")
```

Rather than making requests to multiple API endpoints and manipulating the data to create the dataset that is needed, GraphQL gives the user a lot more flexibility and precision for the data to return. In the link embedded above, you can use the *Explorer* on the left side of the page and use the checkboxes to decide which endpoints and columns from those endpoints to include. The middle section displays the code to use to make the GraphQL request based on the selections made. Once the play button is clicked, the query is executed and the latest results are displayed on the right side of the page. We can use the query created and displayed in the middle section of the page to create the same request using R.

First, we will import the package **`ghql`** which will allow us to interact with a GraphQL endpoint:

<!-- TODO - ADD REFERENCE TO ghql -->

```{r}
# GraphQL R client (https://github.com/ropensci/ghql)
library(ghql)
```

Next, we want to establish a connection with the GraphQL endpoint:

```{r graphql_init_conn}
con <- GraphqlClient$new(
  url = "https://api.spacex.land/graphql/"
)
```

Now we can send a query to the GraphQL endpoint using the example given at https://api.spacex.land/graphql/

First we need to create a new object with an empty query:

```{r, init-query}
graphql_request <- Query$new()
```
<!-- *This object is a special ["class"](http://adv-r.had.co.nz/OO-essentials.html) * -->

Now we can build the request:

```{r first_graphql_request, warning=FALSE, message=FALSE}
graphql_request$query('mydata', '{
  launchesPast(order: "launch_date_local") {
    mission_name
    launch_date_local
    launch_site {
      site_name
      site_name_long
    }
    links {
      article_link
      video_link
    }
  }
}')
```

Finally we can execute the query using `con$exec()` on the request we built above and assign the results to the `spacex_data` object:
```{r}
spacex_data <- con$exec(graphql_request$queries$mydata)
```

Now that we have the results from the request, it will once again be in the JSON format, so like before we can convert the JSON format to a dataframe using the `fromJSON` function from the `jsonlite` package:

```{r}
spacex_data <- fromJSON(spacex_data)
```

The data we retrieved this time has a strange ***nested*** structure, where we have a column like `links` which currently contains both the `article_link` and `video_link` columns. Because of this, the `fromJSON` function will return a list object instead of the expected dataframe. We can clean this up into a workable format by first using the `as_tibble()` function to convert the list to a tibble (which has similar properties to a dataframe, [find out more here](https://r4ds.had.co.nz/tibbles.html)), and using the `unnest()` function on the new result:

```{r, warning=F}
spacex_data <- unnest(as_tibble(spacex_data))
# Show data:
spacex_data
```

We can programmatically show the video associated with the first row from the dataset:
```{r show_spacex_video}
include_graphics(spacex_data$links$video_link[[1]])
```

<!-- Commented out because not relevant to tutorial, but could easily extract the number of views on the video: -->
<!-- ```{r} -->
<!-- library(rvest) -->
<!-- # Read the html page through rvest -->
<!-- youtube_url <- read_html(spacex_data$links$video_link[[1]]) -->
<!-- # Show how many views -->
<!-- as.numeric(html_attr(html_nodes(youtube_url, -->
<!--                                 'meta[itemprop="interactionCount"]'), -->
<!--                      "content")) -->
<!-- ``` -->



### thegraph (GRT)

In the next section we will talk about how to leverage GraphQL to interact with "The Graph Network", which allows us to interact with networks built on the Ethereum blockchain and IPFS.

## the graph - GRT

There are a large number of applications built on Ethereum (most being ["dapps", meaning decentralized applications](https://ethereum.stackexchange.com/questions/383/what-is-a-dapp)), and because they are public blockchains, "the graph" project created a way for developers to make *"subgraphs"* that allow users to query data from smart contracts on the Ethereum blockchain through GraphQL. 

For example, a vibrant virtual world owned by its users is being built on the ["Decentraland" blockchain](https://decentraland.org/), and we can query information relating to things like real estate transactions using the Decentraland subgraph made available by the graph network:

```{r, echo=F}
knitr::include_url('https://thegraph.com/explorer/subgraph/decentraland/marketplace')
```

<!-- There are tools for developers to build subgraphs on any Ethereum smart contract since anything on the Ethereum blockchain is publicly accessible. You can learn more about creating subgraphs at this link: https://thegraph.com/docs/introduction For the purposes of this tutorial -->

### Decentraland Subgraph Request 

Why would we want to request any data from these services in the first place? As mentioned above, users can buy and sell digital real estate on Decentraland. We have been collecting data relating to these real-estate markets [TODO - ADD HERE]

```{r}
library(pins)
board_register(name = "pins_board", 
               url = "https://raw.githubusercontent.com/predictcrypto/pins/master/", 
               board = "datatxt")
```

```{r}
decentraland_data <- pin_get(name = "decentraland_market")
# Show the data 
decentraland_data
```

<!-- *Feel free to use this data endpoint as much as you would like. New data gets added every 12 hours.* -->

The field `createdAt` contains the unix timestamp of when the specific event took place on the Decentraland blockchain. We can convert the number to a proper date-time object several different ways, but one simple option is to use the `anytime` package, which will automatically detect the format and properly convert the column to the correct data type. After importing the package we can use the `anytime()` function on the `createdAt` column, making sure to convert the original value from a string to a number first:
```{r}
library(anytime)
decentraland_data$createdAt <- anytime(as.numeric(decentraland_data$createdAt))
```

Now we can arrange the data from the latest data to the oldest using the `arrange` function and show the data again:
```{r}
decentraland_data <- arrange(decentraland_data, desc(createdAt))
# Show the data
decentraland_data
```

We can view the contents of the `nft_image` and display the image:
```{r}
include_graphics(decentraland_data$nft_image[[1]]) 
```

#### Answering Questions with Data

Let's start by answering some questions relating to the data by comparing the results by the **`category`** field. First, let's group the data by the field:
```{r}
# group data by category
data_by_category <- group_by(decentraland_data, category)
```

First, let's count the number of records by `category` using the `count()` function:
```{r}
count(data_by_category)
```

Now we can calculate the average price by category:
```{r}
summarise(data_by_category, avg_price_mana = mean(price_mana))
```


Next let's visualize the data. First we need to import the `ggplot2` package:
```{r}
library(ggplot2)
```


Now we can plot the prices by category using a bar plot:
```{r}
ggplot(decentraland_data, aes(x=category, y=avg_price_mana)) +
  geom_bar(stat="identity") 
```

The **estate** category is clearly much more expensive than the rest. Let's make a box-plot instead, and make the y-axis a logarithmic scale so we can visually compare the categories:
```{r decentraland_boxplot_categories}
decentraland_boxplot <- ggplot(decentraland_data, aes(x=category, y=price_mana)) +
                          geom_boxplot() +  
                          scale_y_log10()
# Show the visualization:
decentraland_boxplot
```

We can add new elements to the `decentraland_boxplot` chart to make changes to the visual comparison:
```{r}
decentraland_boxplot +
  scale_y_log10() + 
  geom_jitter(position=position_jitter(0.2))
```



Prices over time 

Prices over time - facet by category


<!-- Commented out because does not feel very relevant, might be better to add this as a fun note for the end indead - TODO -->
<!-- We own the digital real estate located at the coordinates (33, 6), which you can visit for yourself by accessing the location within the game: <https://play.decentraland.org/?position=33%2C6> -->

<!-- On a map here is what it looks like: -->
<!-- ```{r} -->
<!-- include_graphics("https://api.decentraland.org/v1/parcels/33/6/map.png") -->
<!-- ``` -->
<!-- *The image above was displayed using the regular API created by Decentraland, you can find the documentation for it here (which is different from the GraphQL subgraph on the graph network): https://docs.decentraland.org/market/api/* -->


<!-- TODO - NOTE 12/29: SHOULD MAKE SCRIPT WHERE I FIND LATEST SOLD ESTATE, SHOW IT ON A MAP AND SHOW THE $ VALUE AFTER FIRST PULLING THE LATEST PRICE OF MANA! INCLUDE FILTERS DIRECTLY IN THE GRAPHQL QUERY TO ONLY RETURN VERY SPECIFICALLY THE URL OF THE ESTATE, AND THE SELLING PRICE, LIMITING TO 1 RESULT THAT WAS A SOLD ESTATE -->


<!-- NOTE 01/08: Perform the last step as described above and ready to publish and share the tutorial! -->

**-- WORK IN PROGRESS**


<!-- TODO - HERE start by doing higher level analysis like for example figuring out the total MANA in the current market how much people are investing and using, and grabbing latest price of MANA to compare it to real $ dollars. Use pins data to analyze and create history over 5-7 days or something along those lines. -->







<!-- Pretty unrelated code below, so commented out: -->
<!-- ### Exercise -->

<!-- The code below can be used to retrieve the coordinates to the Predict Crypto HQ in Decentraland. -->

<!-- 1.  First, run the code to produce the same map as shown above for the coordinates (33, 6). Simply **press the green "Run Code" button to show the results**. -->

<!-- 2.  Then, change the url below to find the center of the map (0, 0) by replacing the numbers 33 and 6 in the link below with 0's. -->

<!-- ```{r show-map, exercise=TRUE, exercise.lines = 2} -->
<!-- include_graphics("https://api.decentraland.org/v1/parcels/33/6/map.png") -->
<!-- ``` -->

<!-- ```{r show-map-hint} -->
<!-- include_graphics("https://api.decentraland.org/v1/parcels/0/0/map.png") -->
<!-- ``` -->

<!-- A copy of the Predict Crypto HQ is also located at the coordinates (120, -21). Feel free to find it on the map using the interactive code chunk above, or navigate to the location inside the game itself: <https://play.decentraland.org/?position=120%2C-21> -->

<!-- You can access the Decentraland game itself below, or by clicking the link above and experiencing it in its own browser window. The url has the coordinates embedded into it, so you will be brought directly to the Predict Crypto HQ within Decentraland. -->

<!-- ```{r decentraland_embed, out.width="100%", echo=FALSE} -->
<!-- include_url('https://play.decentraland.org/?position=33%2C6',height = '550px') -->
<!-- ``` -->






<!-- In case I need to remember syntax for a quiz: -->

<!-- ```{r quiz} -->

<!-- quiz( -->

<!--   question("Which package contains functions for installing other R packages?", -->

<!--     answer("base"), -->

<!--     answer("tools"), -->

<!--     answer("utils", correct = TRUE), -->

<!--     answer("codetools") -->

<!--   ), -->

<!--   question("Which of the R packages listed below are used to create plots?", -->

<!--     answer("lattice", correct = TRUE), -->

<!--     answer("tools"), -->

<!--     answer("stats"), -->

<!--     answer("grid", correct = TRUE) -->

<!--   ) -->

<!-- ) -->

<!-- ``` -->
